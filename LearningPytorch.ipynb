{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZ/lka3YWRYaTu68gu6EDd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/forbiddenvelocity/Learning-Pytorch/blob/main/LearningPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors\n"
      ],
      "metadata": {
        "id": "wgCwjKIDDQaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor - A multidimensional matrix containing elements of a single data type."
      ],
      "metadata": {
        "id": "vqDU-DwsDV3t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPTHDCDsDBkw",
        "outputId": "05239b21-338a-4cdf-8142-803c2fdeb003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "empty(1): tensor([3.1278e-24])\n",
            "empty(3): tensor([ 1.6393e+03,  3.1109e-41, -1.7811e+02])\n",
            "empty(2,3): tensor([[1.6399e+03, 3.1109e-41, 1.6397e+03],\n",
            "        [3.1109e-41, 1.1210e-43, 0.0000e+00]])\n",
            "empty(2,2,3): tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "        [[0.0000e+00, 0.0000e+00, 1.4013e-45],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]])\n",
            "rand(5,3): tensor([[0.6482, 0.2828, 0.9649],\n",
            "        [0.3674, 0.3985, 0.9481],\n",
            "        [0.9759, 0.4661, 0.2474],\n",
            "        [0.1687, 0.1231, 0.8295],\n",
            "        [0.0983, 0.6325, 0.7223]])\n",
            "zeros(5,3): tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "ones(5,3): tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "#torch.empty(size): uninitiallized\n",
        "x = torch.empty(1) #scalar\n",
        "print(\"empty(1):\", x)\n",
        "x = torch.empty(3) #vector\n",
        "print(\"empty(3):\", x)\n",
        "x = torch.empty(2, 3) #matrix\n",
        "print(\"empty(2,3):\", x)\n",
        "x = torch.empty(2, 2, 3 ) #tensor\n",
        "print(\"empty(2,2,3):\", x)\n",
        "x = torch.rand(5, 3) #random matrix\n",
        "print(\"rand(5,3):\", x)\n",
        "\n",
        "#torch.zeros(size), fill with 0s\n",
        "#torch.ones(size), fill with 1s\n",
        "x = torch.zeros(5, 3)\n",
        "print(\"zeros(5,3):\", x)\n",
        "x = torch.ones(5, 3)\n",
        "print(\"ones(5,3):\", x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#size\n",
        "print(\"size\", x.size())  #x.size(0)\n",
        "print(\"shape\", x.shape)  #x.shape[0]\n",
        "print(\"dim\", x.dim())  #x.dim()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hix14OTbEdN4",
        "outputId": "58d869c1-37fa-460f-b623-ffca44f43dd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size torch.Size([5, 3])\n",
            "shape torch.Size([5, 3])\n",
            "dim 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data type\n",
        "print(x.dtype)\n",
        "\n",
        "x = torch.zeros(5, 3, dtype=torch.float16)\n",
        "print(x)\n",
        "\n",
        "#check data type\n",
        "print(x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yfQ50tqEmZN",
        "outputId": "1cb90ab2-1c01-433c-d520-493c1b0121c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], dtype=torch.float16)\n",
            "torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# construct from data\n",
        "x = torch.tensor([5.5, 3])\n",
        "print(x, x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRPF9U7cE3zW",
        "outputId": "f1aaede8-93c3-470e-f916-2e21b2a92e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5000, 3.0000]) torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([5.5, 3], requires_grad=True)\n",
        "print(x)\n",
        "#requires_grad argument\n",
        "#This tells pytorch that it will need to calculate the gradietns for this tensor\n",
        "#later in the optimization steps, this is a variable in your model that you want to optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieq3e6akFEJG",
        "outputId": "7b83b28f-891f-49cc-aaaf-cf2185d443e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5000, 3.0000], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Operations with Tensors"
      ],
      "metadata": {
        "id": "xO_N0M3BF6K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(2,2)\n",
        "y = torch.rand(2,2)\n",
        "\n",
        "z = x + y #element wise addition\n",
        "# or torch.add(x,y)\n",
        "# y.add_(x)\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKvgkP7PFcb7",
        "outputId": "42e04f17-fc45-48d8-cddd-3d5470fb1e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[0.3551, 0.3221],\n",
            "        [0.0142, 0.6702]])\n",
            "tensor([[1.3551, 1.3221],\n",
            "        [1.0142, 1.6702]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#subtraction\n",
        "z = x - y\n",
        "z = torch.sub(x,y)\n",
        "\n",
        "#multiplication\n",
        "z = torch.mul(x,y)\n",
        "z = x * y\n",
        "\n",
        "#division\n",
        "z = torch.div(x,y)\n",
        "z = torch.div(x,y)"
      ],
      "metadata": {
        "id": "vNjy3e6fGTHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# slicing\n",
        "x = torch.rand(5,3)\n",
        "print(x)\n",
        "print(\"x[:, 0]\", x[:, 0]) # all rows, column 0\n",
        "print(\"x[1, :]\", x[1, :]) # row 1, all columns\n",
        "print(x[1, 1]) # element at row 1, column 1\n",
        "\n",
        "print(\"x[1,1].item()\", x[1,1].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SANaGdfFGopi",
        "outputId": "6c046842-6406-445a-8961-8c8b2174baad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9685, 0.5182, 0.8885],\n",
            "        [0.3594, 0.5325, 0.5461],\n",
            "        [0.5271, 0.1268, 0.9829],\n",
            "        [0.2516, 0.8708, 0.7997],\n",
            "        [0.8452, 0.4711, 0.5992]])\n",
            "x[:, 0] tensor([0.9685, 0.3594, 0.5271, 0.2516, 0.8452])\n",
            "x[1, :] tensor([0.3594, 0.5325, 0.5461])\n",
            "tensor(0.5325)\n",
            "x[1,1].item() 0.5324912667274475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshaping with torch.view()\n",
        "x = torch.randn(4,4)\n",
        "print(x)\n",
        "y = x.view(16)\n",
        "z = x.view(-1,8)\n",
        "print(y)\n",
        "print(z)\n",
        "print(z.size(), y.size(), z.size())\n",
        "#"
      ],
      "metadata": {
        "id": "7APu1cWzHHNZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba6a40aa-2efa-447d-9cd4-90233385f6f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3332, -0.2433, -0.1464, -0.1438],\n",
            "        [-0.9129, -0.4019,  1.5588,  0.5908],\n",
            "        [ 1.2441,  1.4796, -0.2553,  0.3944],\n",
            "        [ 1.4202,  0.1795, -0.2441, -1.1942]])\n",
            "tensor([ 0.3332, -0.2433, -0.1464, -0.1438, -0.9129, -0.4019,  1.5588,  0.5908,\n",
            "         1.2441,  1.4796, -0.2553,  0.3944,  1.4202,  0.1795, -0.2441, -1.1942])\n",
            "tensor([[ 0.3332, -0.2433, -0.1464, -0.1438, -0.9129, -0.4019,  1.5588,  0.5908],\n",
            "        [ 1.2441,  1.4796, -0.2553,  0.3944,  1.4202,  0.1795, -0.2441, -1.1942]])\n",
            "torch.Size([2, 8]) torch.Size([16]) torch.Size([2, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numpy"
      ],
      "metadata": {
        "id": "iIuTYrmGFjhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(5)\n",
        "print(a)\n",
        "\n",
        "#torch to numpy with .numpy()\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--7T0rxMFMJV",
        "outputId": "0f52bcb7-5be6-42d8-e14e-dc26152eb625"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Careful: If the Tensor is on the CPU (not the GPU),\n",
        "# both objects will share the same memory location, so changing one\n",
        "# will also change the other\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrCjvxxvF-av",
        "outputId": "a95c5958-5a8e-4eb6-e4cc-eb1f34efa77d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting from numpy to torch with .from_numpy(x), or torch.tensor() to copy it\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "c = torch.tensor(a)\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5k1otXzGs6i",
        "outputId": "931a4bb2-ab5f-4e7c-890f-f3fec13acecc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: By default all tensors are created on the CPU but we can also move them to the GPU, or create them directly on the GPU"
      ],
      "metadata": {
        "id": "gf-nGsPUHOnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "x = torch.rand(2,2).to(device) #move tensors to GPU device\n",
        "\n",
        "x = torch.rand(2,2, device=device) #or directly create them on GPU"
      ],
      "metadata": {
        "id": "GTNz8dwmHGAA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "blMk0RPoHwU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd"
      ],
      "metadata": {
        "id": "Gw8XzCJoH6wS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The autograd package provides automatic differentiation for all operations on tensors. torch.autograd is an enginer for computing vector-jacobian product. It computes partial derivatives while applying the chain rule.\n",
        "\n",
        "Set requires_grad = True"
      ],
      "metadata": {
        "id": "2r3UA_xAH_fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "#requires_grad = True -> tracks all operations on the tensors.\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "y = x + 2\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "print(y.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pAgYop8IcoT",
        "outputId": "4c7b00fd-0fee-4850-f1fa-1b342e922829"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.1987, -1.6719,  1.7511], requires_grad=True)\n",
            "tensor([2.1987, 0.3281, 3.7511], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x7bfcc9e6f670>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = y * y * 3\n",
        "print(z)\n",
        "z = z.mean()\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-MBOsneJMUI",
        "outputId": "61e00493-b481-458e-f14a-2d32937e50f3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([14.5027,  0.3229, 42.2114], grad_fn=<MulBackward0>)\n",
            "tensor(19.0123, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uLb6vg7YJT1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to stop a tensor from tracking history?\n",
        "\n",
        "During training loop when we want to update our weights, or after training during evaluation. These operations should not be part of the gradient computation. To prevent this, we can use:\n",
        "\n",
        "x.requires_grad_(False)\n",
        "x.detach()\n",
        "wrap in with torch.no-grad():"
      ],
      "metadata": {
        "id": "8Sl_9CGnJmHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(2, 2)\n",
        "b = (a * a).sum()\n",
        "print(a.requires_grad)\n",
        "print(b.grad_fn)\n",
        "\n",
        "# .requires_grad_(..) changes an existing flag in place\n",
        "a.requires_grad_(True)\n",
        "b = (a * a).sum()\n",
        "print(a.requires_grad)\n",
        "print(b.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQNI1M-DKA2Q",
        "outputId": "7ebf9bda-bc02-4be7-a31a-7ad3ec866627"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "None\n",
            "True\n",
            "<SumBackward0 object at 0x7bfcd44c1330>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .detach(): get a new tensor with the same content but no gradeint computation:\n",
        "a = torch.randn(2, 2, requires_grad = True)\n",
        "b = a.detach()\n",
        "print(a.requires_grad)\n",
        "print(b.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnUQbSsqKWsl",
        "outputId": "38f0c172-a0ae-49fa-9b02-320905cba8da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wrap in 'with torch.no_grad():'\n",
        "a = torch.randn(2, 2, requires_grad = True)\n",
        "print(a.requires_grad)\n",
        "with torch.no_grad():\n",
        "    b = a * a\n",
        "    print(b.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2t9Tt7zK3iA",
        "outputId": "17b4d11b-f2d3-416e-9500-cd2bbdb28d61"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent Autograd"
      ],
      "metadata": {
        "id": "2__kGyThLPUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression Example:\n",
        "𝑓\n",
        "(\n",
        "𝑥\n",
        ")\n",
        "=\n",
        "𝑤\n",
        "⋅\n",
        "𝑥\n",
        "+\n",
        "𝑏\n",
        "\n",
        "and f(x) = 2 * x\n"
      ],
      "metadata": {
        "id": "gCTIZJQ3LVIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "#linear regression\n",
        "#f = w * x + b\n",
        "# f = 2 * x\n",
        "\n",
        "X = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8, 10, 12, 14, 16], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "  return ((y_pred - y) ** 2).mean()\n",
        "\n",
        "X_test = 5.0\n",
        "\n",
        "print(f'Prediction before training: f({X_test}) = {forward(X_test):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkdvXkMGLyMr",
        "outputId": "87258615-780d-459c-8c1d-dd08a950bfc8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5.0) = 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training it\n",
        "learning_rate = 0.01\n",
        "n_epochs = 100\n",
        "\n",
        "for epochs in range(n_epochs):\n",
        "  #forward pass and loss\n",
        "  y_pred = forward(X)\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  #backward pass\n",
        "  l.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "\n",
        "  w.grad.zero_()\n",
        "\n",
        "  if epochs % 10 == 0:\n",
        "    print(f'epoch {epochs+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f({X_test}) = {forward(X_test):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLQlLPahLNux",
        "outputId": "7a13e98c-5f41-4626-8e16-279a5bc03f68"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: w = 2.040, loss = 102.00000000\n",
            "epoch 11: w = 2.000, loss = 0.00000011\n",
            "epoch 21: w = 2.000, loss = 0.00000000\n",
            "epoch 31: w = 2.000, loss = 0.00000000\n",
            "epoch 41: w = 2.000, loss = 0.00000000\n",
            "epoch 51: w = 2.000, loss = 0.00000000\n",
            "epoch 61: w = 2.000, loss = 0.00000000\n",
            "epoch 71: w = 2.000, loss = 0.00000000\n",
            "epoch 81: w = 2.000, loss = 0.00000000\n",
            "epoch 91: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5.0) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pat60vddNF_i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}