{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyeFC5X8YuzGFJARCPYlE/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/forbiddenvelocity/Learning-Pytorch/blob/main/LearningPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors\n"
      ],
      "metadata": {
        "id": "wgCwjKIDDQaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor - A multidimensional matrix containing elements of a single data type."
      ],
      "metadata": {
        "id": "vqDU-DwsDV3t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPTHDCDsDBkw",
        "outputId": "05239b21-338a-4cdf-8142-803c2fdeb003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "empty(1): tensor([3.1278e-24])\n",
            "empty(3): tensor([ 1.6393e+03,  3.1109e-41, -1.7811e+02])\n",
            "empty(2,3): tensor([[1.6399e+03, 3.1109e-41, 1.6397e+03],\n",
            "        [3.1109e-41, 1.1210e-43, 0.0000e+00]])\n",
            "empty(2,2,3): tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "        [[0.0000e+00, 0.0000e+00, 1.4013e-45],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]])\n",
            "rand(5,3): tensor([[0.6482, 0.2828, 0.9649],\n",
            "        [0.3674, 0.3985, 0.9481],\n",
            "        [0.9759, 0.4661, 0.2474],\n",
            "        [0.1687, 0.1231, 0.8295],\n",
            "        [0.0983, 0.6325, 0.7223]])\n",
            "zeros(5,3): tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "ones(5,3): tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "#torch.empty(size): uninitiallized\n",
        "x = torch.empty(1) #scalar\n",
        "print(\"empty(1):\", x)\n",
        "x = torch.empty(3) #vector\n",
        "print(\"empty(3):\", x)\n",
        "x = torch.empty(2, 3) #matrix\n",
        "print(\"empty(2,3):\", x)\n",
        "x = torch.empty(2, 2, 3 ) #tensor\n",
        "print(\"empty(2,2,3):\", x)\n",
        "x = torch.rand(5, 3) #random matrix\n",
        "print(\"rand(5,3):\", x)\n",
        "\n",
        "#torch.zeros(size), fill with 0s\n",
        "#torch.ones(size), fill with 1s\n",
        "x = torch.zeros(5, 3)\n",
        "print(\"zeros(5,3):\", x)\n",
        "x = torch.ones(5, 3)\n",
        "print(\"ones(5,3):\", x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#size\n",
        "print(\"size\", x.size())  #x.size(0)\n",
        "print(\"shape\", x.shape)  #x.shape[0]\n",
        "print(\"dim\", x.dim())  #x.dim()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hix14OTbEdN4",
        "outputId": "58d869c1-37fa-460f-b623-ffca44f43dd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size torch.Size([5, 3])\n",
            "shape torch.Size([5, 3])\n",
            "dim 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data type\n",
        "print(x.dtype)\n",
        "\n",
        "x = torch.zeros(5, 3, dtype=torch.float16)\n",
        "print(x)\n",
        "\n",
        "#check data type\n",
        "print(x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yfQ50tqEmZN",
        "outputId": "1cb90ab2-1c01-433c-d520-493c1b0121c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], dtype=torch.float16)\n",
            "torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# construct from data\n",
        "x = torch.tensor([5.5, 3])\n",
        "print(x, x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRPF9U7cE3zW",
        "outputId": "f1aaede8-93c3-470e-f916-2e21b2a92e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5000, 3.0000]) torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([5.5, 3], requires_grad=True)\n",
        "print(x)\n",
        "#requires_grad argument\n",
        "#This tells pytorch that it will need to calculate the gradietns for this tensor\n",
        "#later in the optimization steps, this is a variable in your model that you want to optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieq3e6akFEJG",
        "outputId": "7b83b28f-891f-49cc-aaaf-cf2185d443e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5000, 3.0000], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Operations with Tensors"
      ],
      "metadata": {
        "id": "xO_N0M3BF6K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(2,2)\n",
        "y = torch.rand(2,2)\n",
        "\n",
        "z = x + y #element wise addition\n",
        "# or torch.add(x,y)\n",
        "# y.add_(x)\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKvgkP7PFcb7",
        "outputId": "42e04f17-fc45-48d8-cddd-3d5470fb1e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[0.3551, 0.3221],\n",
            "        [0.0142, 0.6702]])\n",
            "tensor([[1.3551, 1.3221],\n",
            "        [1.0142, 1.6702]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#subtraction\n",
        "z = x - y\n",
        "z = torch.sub(x,y)\n",
        "\n",
        "#multiplication\n",
        "z = torch.mul(x,y)\n",
        "z = x * y\n",
        "\n",
        "#division\n",
        "z = torch.div(x,y)\n",
        "z = torch.div(x,y)"
      ],
      "metadata": {
        "id": "vNjy3e6fGTHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# slicing\n",
        "x = torch.rand(5,3)\n",
        "print(x)\n",
        "print(\"x[:, 0]\", x[:, 0]) # all rows, column 0\n",
        "print(\"x[1, :]\", x[1, :]) # row 1, all columns\n",
        "print(x[1, 1]) # element at row 1, column 1\n",
        "\n",
        "print(\"x[1,1].item()\", x[1,1].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SANaGdfFGopi",
        "outputId": "6c046842-6406-445a-8961-8c8b2174baad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9685, 0.5182, 0.8885],\n",
            "        [0.3594, 0.5325, 0.5461],\n",
            "        [0.5271, 0.1268, 0.9829],\n",
            "        [0.2516, 0.8708, 0.7997],\n",
            "        [0.8452, 0.4711, 0.5992]])\n",
            "x[:, 0] tensor([0.9685, 0.3594, 0.5271, 0.2516, 0.8452])\n",
            "x[1, :] tensor([0.3594, 0.5325, 0.5461])\n",
            "tensor(0.5325)\n",
            "x[1,1].item() 0.5324912667274475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshaping with torch.view()\n",
        "x = torch.randn(4,4)\n",
        "print(x)\n",
        "y = x.view(16)\n",
        "z = x.view(-1,8)\n",
        "print(y)\n",
        "print(z)\n",
        "print(z.size(), y.size(), z.size())\n",
        "#"
      ],
      "metadata": {
        "id": "7APu1cWzHHNZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba6a40aa-2efa-447d-9cd4-90233385f6f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3332, -0.2433, -0.1464, -0.1438],\n",
            "        [-0.9129, -0.4019,  1.5588,  0.5908],\n",
            "        [ 1.2441,  1.4796, -0.2553,  0.3944],\n",
            "        [ 1.4202,  0.1795, -0.2441, -1.1942]])\n",
            "tensor([ 0.3332, -0.2433, -0.1464, -0.1438, -0.9129, -0.4019,  1.5588,  0.5908,\n",
            "         1.2441,  1.4796, -0.2553,  0.3944,  1.4202,  0.1795, -0.2441, -1.1942])\n",
            "tensor([[ 0.3332, -0.2433, -0.1464, -0.1438, -0.9129, -0.4019,  1.5588,  0.5908],\n",
            "        [ 1.2441,  1.4796, -0.2553,  0.3944,  1.4202,  0.1795, -0.2441, -1.1942]])\n",
            "torch.Size([2, 8]) torch.Size([16]) torch.Size([2, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numpy"
      ],
      "metadata": {
        "id": "iIuTYrmGFjhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(5)\n",
        "print(a)\n",
        "\n",
        "#torch to numpy with .numpy()\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--7T0rxMFMJV",
        "outputId": "0f52bcb7-5be6-42d8-e14e-dc26152eb625"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Careful: If the Tensor is on the CPU (not the GPU),\n",
        "# both objects will share the same memory location, so changing one\n",
        "# will also change the other\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrCjvxxvF-av",
        "outputId": "a95c5958-5a8e-4eb6-e4cc-eb1f34efa77d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting from numpy to torch with .from_numpy(x), or torch.tensor() to copy it\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "c = torch.tensor(a)\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5k1otXzGs6i",
        "outputId": "931a4bb2-ab5f-4e7c-890f-f3fec13acecc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: By default all tensors are created on the CPU but we can also move them to the GPU, or create them directly on the GPU"
      ],
      "metadata": {
        "id": "gf-nGsPUHOnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "x = torch.rand(2,2).to(device) #move tensors to GPU device\n",
        "\n",
        "x = torch.rand(2,2, device=device) #or directly create them on GPU"
      ],
      "metadata": {
        "id": "GTNz8dwmHGAA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "blMk0RPoHwU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd"
      ],
      "metadata": {
        "id": "Gw8XzCJoH6wS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The autograd package provides automatic differentiation for all operations on tensors. torch.autograd is an enginer for computing vector-jacobian product. It computes partial derivatives while applying the chain rule.\n",
        "\n",
        "Set requires_grad = True"
      ],
      "metadata": {
        "id": "2r3UA_xAH_fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "#requires_grad = True -> tracks all operations on the tensors.\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "y = x + 2\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "print(y.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pAgYop8IcoT",
        "outputId": "4c7b00fd-0fee-4850-f1fa-1b342e922829"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.1987, -1.6719,  1.7511], requires_grad=True)\n",
            "tensor([2.1987, 0.3281, 3.7511], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x7bfcc9e6f670>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = y * y * 3\n",
        "print(z)\n",
        "z = z.mean()\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-MBOsneJMUI",
        "outputId": "61e00493-b481-458e-f14a-2d32937e50f3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([14.5027,  0.3229, 42.2114], grad_fn=<MulBackward0>)\n",
            "tensor(19.0123, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uLb6vg7YJT1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to stop a tensor from tracking history?\n",
        "\n",
        "During training loop when we want to update our weights, or after training during evaluation. These operations should not be part of the gradient computation. To prevent this, we can use:\n",
        "\n",
        "x.requires_grad_(False)\n",
        "x.detach()\n",
        "wrap in with torch.no-grad():"
      ],
      "metadata": {
        "id": "8Sl_9CGnJmHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(2, 2)\n",
        "b = (a * a).sum()\n",
        "print(a.requires_grad)\n",
        "print(b.grad_fn)\n",
        "\n",
        "# .requires_grad_(..) changes an existing flag in place\n",
        "a.requires_grad_(True)\n",
        "b = (a * a).sum()\n",
        "print(a.requires_grad)\n",
        "print(b.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQNI1M-DKA2Q",
        "outputId": "7ebf9bda-bc02-4be7-a31a-7ad3ec866627"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "None\n",
            "True\n",
            "<SumBackward0 object at 0x7bfcd44c1330>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .detach(): get a new tensor with the same content but no gradeint computation:\n",
        "a = torch.randn(2, 2, requires_grad = True)\n",
        "b = a.detach()\n",
        "print(a.requires_grad)\n",
        "print(b.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnUQbSsqKWsl",
        "outputId": "38f0c172-a0ae-49fa-9b02-320905cba8da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wrap in 'with torch.no_grad():'\n",
        "a = torch.randn(2, 2, requires_grad = True)\n",
        "print(a.requires_grad)\n",
        "with torch.no_grad():\n",
        "    b = a * a\n",
        "    print(b.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2t9Tt7zK3iA",
        "outputId": "17b4d11b-f2d3-416e-9500-cd2bbdb28d61"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent Autograd"
      ],
      "metadata": {
        "id": "2__kGyThLPUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression Example:\n",
        "𝑓\n",
        "(\n",
        "𝑥\n",
        ")\n",
        "=\n",
        "𝑤\n",
        "⋅\n",
        "𝑥\n",
        "+\n",
        "𝑏\n",
        "\n",
        "and f(x) = 2 * x\n"
      ],
      "metadata": {
        "id": "gCTIZJQ3LVIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "#linear regression\n",
        "#f = w * x + b\n",
        "# f = 2 * x\n",
        "\n",
        "X = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8, 10, 12, 14, 16], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "  return ((y_pred - y) ** 2).mean()\n",
        "\n",
        "X_test = 5.0\n",
        "\n",
        "print(f'Prediction before training: f({X_test}) = {forward(X_test):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkdvXkMGLyMr",
        "outputId": "87258615-780d-459c-8c1d-dd08a950bfc8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5.0) = 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training it\n",
        "learning_rate = 0.01\n",
        "n_epochs = 100\n",
        "\n",
        "for epochs in range(n_epochs):\n",
        "  #forward pass and loss\n",
        "  y_pred = forward(X)\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  #backward pass\n",
        "  l.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "\n",
        "  w.grad.zero_()\n",
        "\n",
        "  if epochs % 10 == 0:\n",
        "    print(f'epoch {epochs+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f({X_test}) = {forward(X_test):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLQlLPahLNux",
        "outputId": "7a13e98c-5f41-4626-8e16-279a5bc03f68"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: w = 2.040, loss = 102.00000000\n",
            "epoch 11: w = 2.000, loss = 0.00000011\n",
            "epoch 21: w = 2.000, loss = 0.00000000\n",
            "epoch 31: w = 2.000, loss = 0.00000000\n",
            "epoch 41: w = 2.000, loss = 0.00000000\n",
            "epoch 51: w = 2.000, loss = 0.00000000\n",
            "epoch 61: w = 2.000, loss = 0.00000000\n",
            "epoch 71: w = 2.000, loss = 0.00000000\n",
            "epoch 81: w = 2.000, loss = 0.00000000\n",
            "epoch 91: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5.0) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model, Loss and Optimizer"
      ],
      "metadata": {
        "id": "42tJ9S33Wl5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A typical pyTorch pipeline looks like this:\n",
        "1. Deisgn Model (input, output, forward pass with different layers)\n",
        "2. Construct loss and optimizer\n",
        "3. Training loop:\n",
        "      Forward = compute prediction and loss\n",
        "      Backward = compute gradients\n",
        "      Update weights"
      ],
      "metadata": {
        "id": "zSvQSThMWxen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([[1], [2], [3], [4], [5], [6], [7], [8]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8], [10], [12], [14], [16]], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(f'n_samples = {n_samples}, n_features = {n_features}')\n",
        "\n",
        "# 0) create a test sample\n",
        "X_test = torch.tensor([5], dtype=torch.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pat60vddNF_i",
        "outputId": "9fe1913f-7397-458b-ff37-537f56d1be80"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_samples = 8, n_features = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design Model, the model has to implement the forward pass!\n",
        "\n",
        "# Here we could simply use a built-in model from PyTorch\n",
        "# model = nn.Linear(input_size, output_size)\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        # define different layers\n",
        "        self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "\n",
        "\n",
        "input_size, output_size = n_features, n_features\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "print(f'Prediction before training: f({X_test.item()}) = {model(X_test).item():.3f}')\n",
        "\n",
        "# 2) Define loss and optimizer\n",
        "learning_rate = 0.01\n",
        "n_epochs = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(n_epochs):\n",
        "    # predict = forward pass with our model\n",
        "    y_predicted = model(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_predicted)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        w, b = model.parameters() # unpack parameters\n",
        "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l.item())\n",
        "\n",
        "print(f'Prediction after training: f({X_test.item()}) = {model(X_test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2EoNGh9Xxaf",
        "outputId": "3092c3cc-e803-40bb-80aa-4c5d1f9e3228"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5.0) = -3.292\n",
            "epoch  10 : w =  2.048314332962036  loss =  0.016520226374268532\n",
            "epoch  20 : w =  2.0478274822235107  loss =  0.015010428614914417\n",
            "epoch  30 : w =  2.045952558517456  loss =  0.013856295496225357\n",
            "epoch  40 : w =  2.0441508293151855  loss =  0.012790915556252003\n",
            "epoch  50 : w =  2.04241943359375  loss =  0.011807420291006565\n",
            "epoch  60 : w =  2.0407559871673584  loss =  0.010899572633206844\n",
            "epoch  70 : w =  2.0391576290130615  loss =  0.010061504319310188\n",
            "epoch  80 : w =  2.0376222133636475  loss =  0.009287838824093342\n",
            "epoch  90 : w =  2.036146879196167  loss =  0.008573701605200768\n",
            "epoch  100 : w =  2.034729480743408  loss =  0.007914495654404163\n",
            "Prediction after training: f(5.0) = 9.978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making First Neural Network!"
      ],
      "metadata": {
        "id": "yd6oUMg0Yx_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "#loading MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "#Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = next(iter(test_loader))\n",
        "example_data, example_targets = examples\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(3,4,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "n-f14LCvY3lF",
        "outputId": "7af16522-1203-448f-b546-1b161e2439bb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAEdCAYAAACsfQVHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAnLklEQVR4nO3df3AU9fnA8SfB5ABJDhJMQiQnqa0iolgjCQFE2mZALSgYHR2dam1HanuhRfxRKSotX2pm6Iy1aoR2pkhrq9Co4G8qEzDUaYJNKm0pmCq1EgfuhGruIBISc5/vH47bfJbkkrvcffZ+vF8zO7PP7d7ew93D8bD7uc9mKKWUAAAAGJLpdAIAACC90HwAAACjaD4AAIBRNB8AAMAomg8AAGAUzQcAADCK5gMAABhF8wEAAIyi+QAAAEbRfAAAAKPi1nzU1dXJpEmTZOTIkVJRUSFvvvlmvF4KCYoagAh1AGoAp8qIx71dNm/eLDfffLOsX79eKioq5OGHH5b6+nppa2uTgoKCsM8NhUJy6NAhycnJkYyMjFinhhhTSsmxY8ekuLhYMjP/18sOpwZEqINkE486oAaSC98FGKgGBto55srLy5XX67Xi3t5eVVxcrGprawd9bnt7uxIRliRb2tvbY1YD1EHyLrGsA2ogORe+C1jsNdCfmF926e7ultbWVqmqqrIey8zMlKqqKmlqajpl/5MnT0owGLQWxU12k1JOTo61HmkNiFAHqWI4dUANpAa+C9C3BgYS8+bj6NGj0tvbK4WFhdrjhYWF4vP5Ttm/trZW3G63tXg8nlinBAP6ng6NtAZEqINUMZw6oAZSA98FGMrlMcd/7bJixQoJBALW0t7e7nRKcAB1AGoAItRBujgt1gccP368jBgxQvx+v/a43++XoqKiU/Z3uVzicrlinQYcFGkNiFAHqYjvAvBdgIHE/MxHdna2lJWVSUNDg/VYKBSShoYGqaysjPXLIQFRAxChDkANIIwhDTeO0KZNm5TL5VIbN25U+/btU0uWLFFjx45VPp9v0OcGAgHHR+qyRL4EAoGY1QB1kLxLLOuAGkjOhe8CFnsN9CcuzYdSSj366KPK4/Go7OxsVV5erpqbm4f0PAotOZf+ii3aGqAOkneJZR1QA8m58F3AMpTmIy6TjA1HMBgUt9vtdBqIUCAQkNzc3JgdjzpITrGsA2ogOfFdgKHUgOO/dgEAAOmF5gMAABhF8wEAAIyK+TwfQDq46667rPVRo0Zp2y688EItvvbaa8Mea926dVpsn3b6ySefjCZFAEhYnPkAAABG0XwAAACjuOwCDMHmzZu1eLBLKX2FQqGw27/zne9ocd87gIqINDY2WusHDx4c8usieZ1zzjla/Pbbb1vrP/jBD7Rtjz76qJGcELnTTz9di3/2s59psf3vfmtrqxZfd911Wvz+++/HMDtnceYDAAAYRfMBAACMovkAAABGMeYD6Mdwxnj0vT4vIvLHP/5Ri7/whS9o8cKFC7X47LPP1uKbbrrJWq+trR1yHkheX/7yl7W477ihDz74wHQ6iNKECRO0+LbbbtNi+3iwsrIyLV6wYIEW19XVxTA7Z3HmAwAAGEXzAQAAjKL5AAAARjHmAxCRSy65RIsXL14cdv9//vOf1vpVV12lbTt69KgWHz9+XIuzs7O1uLm5WYunTZumxfn5+WFzQeq56KKLtLizs9Na37Jli+FsMFRnnHGGFv/mN79xKJPEx5kPAABgFM0HAAAwiuYDAAAYlXZjPuzzNdh/d33o0CEt7urq0uLf//731rrP59O2vfvuu7FIEQ6w/x4/IyNDi/uO8RARmT9/vrV++PDhiF7rzjvv1OIpU6aE3f/ll1+O6PhIPlOnTtXimpoaLX7yySdNpoMIfP/737fWFy1apG0rLy8f1rHnzJmjxZmZ/ztf8Le//U3btmvXrmG9lmmc+QAAAEbRfAAAAKNoPgAAgFEZSinldBJ9BYNBcbvdcTv+v//9by2eNGlS1Mc6duyYFtvHBZhkv9/D2rVrtbilpSWurx8IBCQ3Nzdmx4t3HQzmrLPO0mL7Z/3RRx9FfWz7tVr79X67qqoqa33nzp1Rv64JsawDp2vAJPtYtD/84Q9a/JWvfMVab2xsNJJTtFLtu2Awvb291rr9Xi2R6jumY7Djvf/++1p8/fXXa3Fra+uwchmOodQAZz4AAIBRNB8AAMAomg8AAGBU2s3zYZ/X48ILL9Ti/fv3a/F5552nxRdffLG1PnfuXG3bjBkztLi9vV2LS0pKIsr1008/tdaPHDmibbPPS2F38OBBLY73mI9UY7+eOhx33323Fp9zzjlh99+9e3fYGKnnnnvu0WJ7/fH3N3G88sorWmwfpzEc//3vf7XYfl+ovmPRSktLtW1vvvmmFo8YMSJmecUDZz4AAIBRETcfu3btkoULF0pxcbFkZGTI1q1bte1KKXnggQdkwoQJMmrUKKmqqpJ33nknVvkiCVADoAYgQh1gYBE3H52dnTJt2jSpq6vrd/vatWvlkUcekfXr18vu3bvl9NNPl/nz558yTTlSFzUAagAi1AEGNqx5PjIyMmTLli3WfPZKKSkuLpY777xT7rrrLhH57Pe+hYWFsnHjRrnhhhtOOcbJkyfl5MmTVhwMBiMeG+GUcePGafFFF12kxfbfWU+fPj2i4/f9C/qvf/1L22Yfm5KXl6fFXq9Xi9etWxfRa0fq8991R1MDIsldB3YLFizQ4vr6ei3Ozs7W4g8//FCL7e9Ros/r0FcgEJCcnJy0r4HB2OcXss8/ZP/7Pnny5HinFDOp9l1w2WWXafGGDRu0uO9nGek8H+vXr9fi1157TYsDgYAWf/WrX7XWV65cGfbYfe85IxL/fwP6Mj7Px3vvvSc+n0+bFMntdktFRYU0NTX1+5za2lpxu93WkqpfNukimhoQoQ5SCTUAEeoA4cW0+fj8Lq+FhYXa44WFhafcAfZzK1askEAgYC32X4gguURTAyLUQSqhBiBCHSA8x39q63K5xOVyOZ1GVD7++GMtHmzq64aGhqhfq7q6Wovtl3z+8Y9/aPHmzZujfi0nJHMd2F1yySVabL/MYmf/rJLpMksspVINDMZ+Kt/O/tP6dOJ0HdgviW3atEmLx48fP+Rj2X8y/eyzz2rxT37yEy3+5JNPhny8JUuWaNvOOOMMLbbfYmPkyJFa/Nhjj2lxT09P2NeOtZie+SgqKhIREb/frz3u9/utbUht1ACoAYhQBwgvps1HaWmpFBUVaf/DDwaDsnv3bqmsrIzlSyFBUQOgBiBCHSC8iC+7HD9+XN59910rfu+992TPnj2Sl5cnHo9Hli1bJmvWrJEvfelLUlpaKvfff78UFxdbv4hBavr73/8uHo+HGkhz7e3tcv7551MDaYzvAgxFxM1HS0uLdnvn5cuXi4jILbfcIhs3bpR77rlHOjs7ZcmSJdLR0SGzZ8+Wbdu2nXK9CYMrKCiw1h9//HFtm31K39WrV2vxcG75Ho1LL700bWvAPtHevHnzwu7/29/+Vovvu+++WKfkmAcffFB+//vfp10NROqCCy4Iu91+vT6ZJPt3wWmn6f8sRjLGwz5ey/5z4qNHj0afmOhjPmpra7VtDz30kBaPHj1ai+019cILL2jxgQMHhpVbpCJuPubOnSvhpgbJyMiQ1atXn/KPIVJb3991UwPp6/O5BKiB9MV3AYaCe7sAAACjaD4AAIBRjs/zgYH1nSLd/htu+xwjbW1tRnLCZyZMmGCtz5w5U9tmn6PAfp13zZo1Wmy/bTZSz4wZM7T41ltv1eK33npLi7dv3x73nBAbLS0t1vq3vvUtbdtwx3iEYx+zcdNNN2lxpLfzMI0zHwAAwCiaDwAAYBTNBwAAMIoxHwlk1qxZWnzvvfcOuK99kp69e/fGIyUMoO89GvLz88Pu+7vf/U6LTf+eHs7re2dXEZG8vDwt3rZtmxZ3dXXFPScMjX1OJbuKigpDmegyMjK02J7nYHn/+Mc/1uJvfOMbMclrqDjzAQAAjKL5AAAARtF8AAAAoxjzkUCuvPJKLc7KyrLW+94ZUkSkqanJSE74zFVXXaXFF1988YD7vv7661q8atWqeKSEJDJt2jQttt+i4plnnjGZDsK4/fbbtTgUCjmUSXgLFy7U4i9/+ctabM/bHtvHfJjGmQ8AAGAUzQcAADCK5gMAABjFmA8HjRo1Sosvv/xyLe7u7rbW7eMGenp64pcYTpm740c/+pEW9x2PY7dnzx4t5t4t6aeoqEiLL730Ui2234tpy5Ytcc8JQ2MfS+Ek+z29pkyZYq3bv5MGc+TIES12+t8QznwAAACjaD4AAIBRNB8AAMAoxnw46O6779Zi+++0+97v4c9//rORnPCZO++8U4unT58+4L5bt27VYub1wDe/+U0tLigo0OJXX33VYDZIVitXrtRir9c75Of+5z//0eJbbrlFiw8ePBh1XrHAmQ8AAGAUzQcAADCKyy4Gff3rX9fi+++/X4uDwaAWr169Ou45oX/Lly8f8r41NTVazE9rcdZZZ4Xd/vHHHxvKBMnklVde0eJzzz036mPt27dPi994442ojxUPnPkAAABG0XwAAACjaD4AAIBRjPmII/sU3Y888ogWjxgxQovt1/uam5vjkxhiKi8vT4uHO21xIBAY8Hj2ad3dbnfYY40dO1aLIxnL0tvbq8U//OEPtfiTTz4Z8rHSzYIFC8Juf/HFFw1lgkhlZGRocWZm+P+jX3HFFQNu+9WvfqXFxcXFYY9lf61QKBR2/3ASaZr4/nDmAwAAGBVR81FbWyvTp0+XnJwcKSgokEWLFp1yg6Suri7xer2Sn58vY8aMkerqavH7/TFNGonnnXfe0WLqILUN5ewONQBqAAOJqPlobGwUr9crzc3Nsn37dunp6ZF58+ZJZ2entc8dd9whL774otTX10tjY6McOnRIrrnmmpgnjsSyePFi6iCN2C/JfI4aADWAochQSqlon3zkyBEpKCiQxsZGmTNnjgQCATnjjDPkqaeekmuvvVZERN5++20577zzpKmpSWbMmDHoMYPB4KDXsROVfQyHfcxGWVmZFh84cECLL7/88rDbE10q1UFXV5cW28daxFN9fb0WHz582FovLCzUtl1//fVGchIReeCBB7T4pz/96Sn7vPLKK3LFFVekRA1EYvbs2Vq8c+dOLbZ/N3zta18Lu38yi2UNiJivgzvuuEOL165dG3b/vuM0hjNGw36sSI+3fv16LV66dOmwchmOQCAgubm5YfcZ1piPzwfGfT7grrW1VXp6eqSqqsraZ/LkyeLxeKSpqanfY5w8eVKCwaC2IDlRBxg3bpyIUAPpbDg1IEIdpIuom49QKCTLli2TWbNmydSpU0VExOfzSXZ29ikj7AsLC8Xn8/V7nNraWnG73dZSUlISbUpw0IwZM6gDyJQpU0SEGkhnw6kBEeogXUTdfHi9Xtm7d69s2rRpWAmsWLFCAoGAtbS3tw/reHDGhg0bhvV86gDUAESog3QR1TwfNTU18tJLL8muXbtk4sSJ1uNFRUXS3d0tHR0dWrfr9/ulqKio32O5XC5xuVzRpJFwzj77bC22j/Gws8+5kGxjPPo688wzrfVUqAP7nCtXX321sde+7rrron7up59+qsWDXTN+4YUXtLilpWXAff/0pz8NOY9UqIFILF68WIvtYzzeeustLd61a1fcc3JaNDUg4nwdPPfcc1p89913a/EZZ5xhLJcjR45o8f79+631JUuWaNv6jg1LBhGd+VBKSU1NjWzZskV27NghpaWl2vaysjLJysqShoYG67G2tjY5ePCgVFZWxiZjJDzqIPUNNk6dGgA1gHAiOvPh9Xrlqaeekueff15ycnKs63Zut1tGjRolbrdbvv3tb8vy5cslLy9PcnNzZenSpVJZWTnkkc1ITn6/X7KysqiDNPGf//yn38dPnDghubm51EAaowYwFBGd+Vi3bp0EAgGZO3euTJgwwVo2b95s7fPzn/9cFixYINXV1TJnzhwpKio65TQWUs8555xDHaSRgSaK6vsZUwPpiRrAUAxrno94SKbf9p911lla3NjYqMUej0eL7dcOH3roIS1OsI8iIkP5XXckEq0O7rnnHi2OZN6P888/X4sjnZuj72Degc44fO7ZZ5/V4rfffjui1xquWNZBotWA3ejRo6311tZWbdu5556rxStXrtTi2tra+CXmsFT7LpgzZ44WL1q0SIt/8IMfWOuxnufj+9//vhbX1dUN6/imxH2eDwAAgEjRfAAAAKNoPgAAgFFRzfOBz9h/Z20f42FnHxOSzGM80s1g93eIxI033hizY8E5fe/s+/HHH2vb7POn/OIXvzCSE2LPPieLPX7ttdesdfu/CQsXLtRie1386le/0uKMjAwt3rdvX2TJJhHOfAAAAKNoPgAAgFE0HwAAwCjGfERo9uzZ1vrSpUsdzASAk/qO+Zg5c6aDmcBJ27Zt63cd4XHmAwAAGEXzAQAAjOKyS4QuvfRSa33MmDFh9z1w4IAWHz9+PC45AQCQTDjzAQAAjKL5AAAARtF8AAAAoxjzEUN/+9vftPhrX/uaFn/00Ucm0wEAICFx5gMAABhF8wEAAIyi+QAAAEZlqAS7r3swGBS32+10GohQIBCQ3NzcmB2POkhOsawDaiA58V2AodQAZz4AAIBRNB8AAMCohGs+EuwqEIYo1p8bdZCcYvm5UQPJie8CDOUzS7jm49ixY06ngCjE+nOjDpJTLD83aiA58V2AoXxmCTfgNBQKyaFDh0QpJR6PR9rb22M6eCmVBYNBKSkpMfqeKaXk2LFjUlxcLJmZsetlqYPopUodUAPRS5UaEPmsDtra2mTKlCnUQAQSvQYSbobTzMxMmThxogSDQRERyc3NpdgiZPo9i8dIdOpg+JK9DqiB4Uv2GhD5rA7OPPNMEaEGopGoNZBwl10AAEBqo/kAAABGJWzz4XK5ZNWqVeJyuZxOJWmk4nuWin+meEu19yzV/jwmpNp7lmp/HhMS/T1LuAGnAAAgtSXsmQ8AAJCaaD4AAIBRNB8AAMAomg8AAGBUwjYfdXV1MmnSJBk5cqRUVFTIm2++6XRKCaO2tlamT58uOTk5UlBQIIsWLZK2tjZtn66uLvF6vZKfny9jxoyR6upq8fv9DmUcHWpgYOlSAyLUwUCoAYgkcR2oBLRp0yaVnZ2tNmzYoP75z3+q2267TY0dO1b5/X6nU0sI8+fPV0888YTau3ev2rNnj7ryyiuVx+NRx48ft/a5/fbbVUlJiWpoaFAtLS1qxowZaubMmQ5mHRlqILx0qAGlqINwqAFqQKnkrYOEbD7Ky8uV1+u14t7eXlVcXKxqa2sdzCpxffjhh0pEVGNjo1JKqY6ODpWVlaXq6+utffbv369ERDU1NTmVZkSogcikYg0oRR1EghqAUslTBwl32aW7u1taW1ulqqrKeiwzM1OqqqqkqanJwcwSVyAQEBGRvLw8ERFpbW2Vnp4e7T2cPHmyeDyepHgPqYHIpVoNiFAHkaIGIJI8dZBwzcfRo0elt7dXCgsLtccLCwvF5/M5lFXiCoVCsmzZMpk1a5ZMnTpVRER8Pp9kZ2fL2LFjtX2T5T2kBiKTijUgQh1EghqASHLVQcLd1RaR8Xq9snfvXnnjjTecTgUOoQZADUAkueog4c58jB8/XkaMGHHKSFy/3y9FRUUOZZWYampq5KWXXpKdO3fKxIkTrceLioqku7tbOjo6tP2T5T2kBoYuVWtAhDoYKmoAIslXBwnXfGRnZ0tZWZk0NDRYj4VCIWloaJDKykoHM0scSimpqamRLVu2yI4dO6S0tFTbXlZWJllZWdp72NbWJgcPHkyK95AaGFyq14AIdTAYaiA5/gzxlrR14NhQ1zA2bdqkXC6X2rhxo9q3b59asmSJGjt2rPL5fE6nlhC++93vKrfbrV5//XV1+PBha/nkk0+sfW6//Xbl8XjUjh07VEtLi6qsrFSVlZUOZh0ZaiC8dKgBpaiDcKgBakCp5K2DuDUfjz32mDrrrLOUy+VS5eXlavfu3RE9/9FHH1Uej0dlZ2er8vJy1dzcHKdMk4+I9Ls88cQT1j4nTpxQ3/ve99S4cePU6NGj1eLFi9Xhw4eN5kkNxE+y1EAsUAf9owagVPLWQYZSSsX6bMrmzZvl5ptvlvXr10tFRYU8/PDDUl9fL21tbVJQUBD2uaFQSA4dOiQ5OTmSkZER69QQY0opOXbsmBQXF0tm5v+u4g2nBkSog2QzUB0AQH/i0nxUVFTI9OnT5bHHHhORz/4hKSkpkaVLl8q9994b9rkffPCBlJSUxDolxFl7e7s2yGk4NSBCHSQrex0AQH9i/l+USCeFOXnypASDQWuJQy8EA3Jycqz1aCYGog5SQ986AICBxLz5iHRSmNraWnG73dbi8XhinRIM6HtpJJqJgaiD1MAlMgBD4fjF2RUrVkggELCW9vZ2p1OCA6gDAEgfMZ/hNNJJYVwul7hcrlinAQdFMzEQdQAA6SPmZz6YFAbUAAAgnLjc22X58uVyyy23yCWXXCLl5eXy8MMPS2dnp9x6663xeDkkIGoAADCQuDQf119/vRw5ckQeeOAB8fl8ctFFF8m2bdtOGYCI1EUNAAAGEpd5PoYjGAyK2+12Og1EKBAISG5ubsyORx0kp1jXAYDU5PivXQAAQHqh+QAAAEbRfAAAAKNoPgAAgFE0HwAAwCiaDwAAYBTNBwAAMIrmAwAAGEXzAQAAjKL5AAAARsXl3i6p7OKLL7bWn3vuOW3bpEmTjOUxb948Ld6/f78Wt7e3G8sFsbVw4UItfuGFF6z1mpoabdv69eu1uLe3N36JAUCMcOYDAAAYRfMBAACMovkAAABGMeYjQvPnz7fWXS6XY3nYxwV861vf0uIbbrjBZDoYhvz8fC1+/PHHB9z3scce0+INGzZo8YkTJ2KXGADECWc+AACAUTQfAADAKJoPAABgFGM+BnHaafpbdOWVVzqUia61tVWLly9frsWnn366Fnd2dsY9J0Rnzpw5Wjxx4sQB93366ae1uKurKy45AUA8ceYDAAAYRfMBAACMovkAAABGMeZjEF/5yle0uLKy0lpfu3at6XQs48aN0+IpU6Zo8ejRo7WYMR+Jwz4/zMqVK4f83CeffFKLlVIxyQkATOLMBwAAMIrmAwAAGEXzAQAAjGLMh83UqVO12D6vwoEDB6z1Bx980EhO/bn66qsde20MzwUXXKDFZWVlYff/9NNPrfVXX301LjkBgEmc+QAAAEZF3Hzs2rVLFi5cKMXFxZKRkSFbt27Vtiul5IEHHpAJEybIqFGjpKqqSt55551Y5YskQA0AAMKJuPno7OyUadOmSV1dXb/b165dK4888oisX79edu/eLaeffrrMnz+faaDTCDUAAAgn4jEfV1xxhVxxxRX9blNKycMPPyz33XefNSbht7/9rRQWFsrWrVvlhhtuGF62Btx3331abL9HyuWXX26tHz9+3EhOIiJ5eXlafNlll2lxKBQylks4qVAD8VZdXR3R/q+99lqcMgEAZ8R0zMd7770nPp9PqqqqrMfcbrdUVFRIU1NTv885efKkBINBbUHyiqYGRKgDAEgnMW0+fD6fiIgUFhZqjxcWFlrb7Gpra8XtdltLSUlJLFOCYdHUgAh1AADpxPGf2q5YsUK7HXwwGDT6D8+1116rxVdeeaUWv/vuu1rc0tIS95z6Y5+C236Z5fXXX9fijo6OOGcUW07XgUlz5swJu727u1uLI5l+HQCSQUzPfBQVFYmIiN/v1x73+/3WNjuXyyW5ubnaguQVTQ2IUAcAkE5i2nyUlpZKUVGRNDQ0WI8Fg0HZvXu3dkM2pC5qAAAwmIgvuxw/fly7FPHee+/Jnj17JC8vTzwejyxbtkzWrFkjX/rSl6S0tFTuv/9+KS4ulkWLFsUybySYv//97+LxeKgBAMCgIm4+WlpatNvMf36d/pZbbpGNGzfKPffcI52dnbJkyRLp6OiQ2bNny7Zt22TkyJGxyzqGrrvuOi2234r+8ccfN5mOZtKkSdb6TTfdpG3r7e3V4jVr1mhxT09P3PLqz6WXXpq0NRBvM2fODBvbdXZ2avGePXtinRIAOCri5mPu3LmilBpwe0ZGhqxevVpWr149rMSQXAKBgDVOgxoAAITDvV0AAIBRNB8AAMAox+f5MM3tdmvxjBkzwu6/bt26eKYT1pIlS6z18ePHa9v279+vxTt37jSSEyI3ffr0iPZ3suYAwATOfAAAAKNoPgAAgFE0HwAAwKi0G/Phcrm0+Mwzz9Tip59+2mQ6YZ199tkDbtu7d6/BTDAcl1xySdjt9vvwMOYDQKrjzAcAADCK5gMAABhF8wEAAIxKuzEfx44d02L7fTMuvPBCLc7Ly9Pijz76KC55iYgUFBRo8bXXXjvgvm+88Ubc8sDwzJ49W4tvvPHGsPsHAgEt/uCDD2KeEwAkEs58AAAAo2g+AACAUTQfAADAqLQb83HixAktPnDggBZXV1dr8csvv6zFDz30UNSvPXXqVC3+whe+oMWTJk3SYqXUgMcKhUJR54H4ys/P1+LMzPA9/vbt2+OZDgAkHM58AAAAo2g+AACAUTQfAADAqLQb82G3atUqLc7IyNDir3/961o8nHu/HD16VIvtYzrGjx8/5GNt3Lgx6jwQX+HmZxE59V4uv/zlL+OYDQAkHs58AAAAo2g+AACAURkq3O85HRAMBsXtdjudhuWiiy7S4i9+8YtRH+uZZ54Ju/03v/mNFt90000D7nvaaYl1xSwQCEhubm7MjpdodRDOxIkTtfj999/XYvtPbffu3avFF1xwQXwSc0Cs6wBAauLMBwAAMIrmAwAAGEXzAQAAjEqsgQMJaM+ePWHjWPr3v/895H3tU7XbxxHAnJkzZ2rxYNOpb926NY7ZAEDi48wHAAAwKqLmo7a2VqZPny45OTlSUFAgixYtkra2Nm2frq4u8Xq9kp+fL2PGjJHq6mrx+/0xTRqJ55133tFi6gAAMJCImo/Gxkbxer3S3Nws27dvl56eHpk3b550dnZa+9xxxx3y4osvSn19vTQ2NsqhQ4fkmmuuiXniSCyLFy+mDgAAQxLRmI9t27Zp8caNG6WgoEBaW1tlzpw5EggE5Ne//rU89dRT8tWvflVERJ544gk577zzpLm5WWbMmBG7zFOQfWp3e9xXoo3xaG9vT9s6yM/PD7vdPq3+L37xi3imAwAJb1hjPgKBgIiI5OXliYhIa2ur9PT0SFVVlbXP5MmTxePxSFNTU7/HOHnypASDQW1BcqIOAABDEXXzEQqFZNmyZTJr1izrlxc+n0+ys7Nl7Nix2r6FhYXi8/n6PU5tba243W5rKSkpiTYlOGjGjBnUAQBgSKJuPrxer+zdu1c2bdo0rARWrFghgUDAWtrb24d1PDhjw4YNw3o+dQAA6SOqeT5qamrkpZdekl27dmn3tSgqKpLu7m7p6OjQ/tfr9/ulqKio32O5XC5xuVzRpJFy7LfZSbDb7oR15plnWuvpVgfz588Pu/3gwYNa/PnlSgBIVxGd+VBKSU1NjWzZskV27NghpaWl2vaysjLJysqShoYG67G2tjY5ePCgVFZWxiZjJDzqAAAQTkRnPrxerzz11FPy/PPPS05OjnX93u12y6hRo8Ttdsu3v/1tWb58ueTl5Ulubq4sXbpUKisrU+4XDtD5/X7JysqiDgAAg4rozMe6deskEAjI3LlzZcKECdayefNma5+f//znsmDBAqmurpY5c+ZIUVGRPPfcczFPHInlnHPOoQ4AAEMS0ZmPoYxBGDlypNTV1UldXV3USaWrkSNHDrjtxIkTBjOJXCAQkNzcXCtO9TrIysqy1s8+++yw+3Z1dWlxT09PXHICgGTBvV0AAIBRNB8AAMAomg8AAGBUVPN8ID5uvfVWLe7o6LDW/+///s9wNggnFApZ6y0tLdq2z2d6/dy7775rJCcASBac+QAAAEbRfAAAAKNoPgAAgFGM+Uggf/nLX7T4oYcestZ37txpOh2E0dvba62vXLlS22afD6e1tdVITgCQLDjzAQAAjKL5AAAARmWoBLtvezAYFLfb7XQaiJB9evXhog6SU6zrAEBq4swHAAAwiuYDAAAYRfMBAACMovkAAABG0XwAAACjaD4AAIBRNB8AAMAomg8AAGAUzQcAADCK5gMAABiVcM1Hgs32jiGK9edGHSQnPjcAQ5FwzcexY8ecTgFRiPXnRh0kJz43AEORcDeWC4VCcujQIVFKicfjkfb2dm5UNUTBYFBKSkqMvmdKKTl27JgUFxdLZmbselnqIHqpVAcAUtNpTidgl5mZKRMnTpRgMCgiIrm5ufyjEyHT71k87j5LHQxfKtQBgNTEf1EAAIBRNB8AAMCohG0+XC6XrFq1Slwul9OpJI1UfM9S8c8Ub7xnABJdwg04BQAAqS1hz3wAAIDURPMBAACMovkAAABG0XwAAACjaD4AAIBRCdt81NXVyaRJk2TkyJFSUVEhb775ptMpJYza2lqZPn265OTkSEFBgSxatEja2tq0fbq6usTr9Up+fr6MGTNGqqurxe/3O5RxdKiBgaVLDQBITQnZfGzevFmWL18uq1atkr/+9a8ybdo0mT9/vnz44YdOp5YQGhsbxev1SnNzs2zfvl16enpk3rx50tnZae1zxx13yIsvvij19fXS2Ngohw4dkmuuucbBrCNDDYSXDjUAIIWpBFReXq68Xq8V9/b2quLiYlVbW+tgVonrww8/VCKiGhsblVJKdXR0qKysLFVfX2/ts3//fiUiqqmpyak0I0INRCYVawBA6kq4Mx/d3d3S2toqVVVV1mOZmZlSVVUlTU1NDmaWuAKBgIiI5OXliYhIa2ur9PT0aO/h5MmTxePxJMV7SA1ELtVqAEBqS7jm4+jRo9Lb2yuFhYXa44WFheLz+RzKKnGFQiFZtmyZzJo1S6ZOnSoiIj6fT7Kzs2Xs2LHavsnyHlIDkUnFGgCQ2k5zOgEMj9frlb1798obb7zhdCpwCDUAINkk3JmP8ePHy4gRI04Zle/3+6WoqMihrBJTTU2NvPTSS7Jz506ZOHGi9XhRUZF0d3dLR0eHtn+yvIfUwNClag0ASG0J13xkZ2dLWVmZNDQ0WI+FQiFpaGiQyspKBzNLHEopqampkS1btsiOHTuktLRU215WViZZWVnae9jW1iYHDx5MiveQGhhcqtcAgBTn9IjX/mzatEm5XC61ceNGtW/fPrVkyRI1duxY5fP5nE4tIXz3u99Vbrdbvf766+rw4cPW8sknn1j73H777crj8agdO3aolpYWVVlZqSorKx3MOjLUQHjpUAMAUldCNh9KKfXoo48qj8ejsrOzVXl5uWpubnY6pYQhIv0uTzzxhLXPiRMn1Pe+9z01btw4NXr0aLV48WJ1+PBh55KOAjUwsHSpAQCpKUMppZw55wIAANJRwo35AAAAqY3mAwAAGEXzAQAAjKL5AAAARtF8AAAAo2g+AACAUTQfAADAKJoPAABgFM0HAAAwiuYDAAAYRfMBAACM+n+/wcBe7IaCXgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        return out\n",
        "\n",
        "model = NeuralNetwork(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "      images = images.reshape(-1, 28*28).to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6tIqRzOanWr",
        "outputId": "936eb1ad-e8e2-446f-9276-bbcc246cbc97"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 0.2029\n",
            "Epoch [1/5], Step [200/600], Loss: 0.2619\n",
            "Epoch [1/5], Step [300/600], Loss: 0.2340\n",
            "Epoch [1/5], Step [400/600], Loss: 0.1196\n",
            "Epoch [1/5], Step [500/600], Loss: 0.2160\n",
            "Epoch [1/5], Step [600/600], Loss: 0.0967\n",
            "Epoch [2/5], Step [100/600], Loss: 0.1938\n",
            "Epoch [2/5], Step [200/600], Loss: 0.0533\n",
            "Epoch [2/5], Step [300/600], Loss: 0.0404\n",
            "Epoch [2/5], Step [400/600], Loss: 0.2300\n",
            "Epoch [2/5], Step [500/600], Loss: 0.0710\n",
            "Epoch [2/5], Step [600/600], Loss: 0.0298\n",
            "Epoch [3/5], Step [100/600], Loss: 0.0826\n",
            "Epoch [3/5], Step [200/600], Loss: 0.0649\n",
            "Epoch [3/5], Step [300/600], Loss: 0.1030\n",
            "Epoch [3/5], Step [400/600], Loss: 0.0575\n",
            "Epoch [3/5], Step [500/600], Loss: 0.0458\n",
            "Epoch [3/5], Step [600/600], Loss: 0.0563\n",
            "Epoch [4/5], Step [100/600], Loss: 0.0544\n",
            "Epoch [4/5], Step [200/600], Loss: 0.0341\n",
            "Epoch [4/5], Step [300/600], Loss: 0.1179\n",
            "Epoch [4/5], Step [400/600], Loss: 0.0806\n",
            "Epoch [4/5], Step [500/600], Loss: 0.0485\n",
            "Epoch [4/5], Step [600/600], Loss: 0.0281\n",
            "Epoch [5/5], Step [100/600], Loss: 0.0444\n",
            "Epoch [5/5], Step [200/600], Loss: 0.0553\n",
            "Epoch [5/5], Step [300/600], Loss: 0.0045\n",
            "Epoch [5/5], Step [400/600], Loss: 0.0633\n",
            "Epoch [5/5], Step [500/600], Loss: 0.0365\n",
            "Epoch [5/5], Step [600/600], Loss: 0.0157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = len(test_loader.dataset)\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN8YJ15sbP0k",
        "outputId": "f6d2711e-d2f4-4a6d-ac61-3ac1b222912b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 97.84 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MKvcot3Ab8DM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}